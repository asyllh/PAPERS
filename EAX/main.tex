\documentclass{elsarticle}
\input{includes/preamble.tex}

\begin{document}
	
\begin{frontmatter}
\title{An Evolutionary Algorithm for the Score-Constrained Strip-Packing Problem}
\author{Asyl L. Hawa}
\author{Rhyd Lewis}
\author{Jonathan M. Thompson}
\address{School of Mathematics, Cardiff University, Senghennydd Road, Cardiff, UK}
\begin{abstract}
\note{Type of packing problem in which order and orientation of items is important. Paper investigates heuristics, EA, postoptimisation.}
\end{abstract}	
\end{frontmatter}

%--------------------------------------------------------------------------------------

\section{Introduction}
\label{sec:intro}

In operational research, many problems involve the grouping of elements into subsets. These types of problems can be seen in packing, scheduling, graph colouring, partioning \intro{examples of grouping problems}.

More formally, given a set $\mathcal{I}$ of $n$ elements, the aim is to produce a partition of subsets $\mathcal{S} = \{S_1, S_2,...,S_k\}$ such that
\begin{subequations}
	\begin{alignat}{2}
	\bigcup\nolimits_{i=1}^{k} S_i &= \mathcal{I}, & \label{eqn:allpacked}\\[3pt]
	S_i \cap S_j &= \emptyset &\quad &\forall \hspace{1mm} i, j \in \{1, 2,\dotsc,k\}, \hspace{1mm} i \neq j, \label{eqn:nointersect}\\[3pt]
	S_i &\in \mathcal{F} & &\forall \hspace{1mm} i \in \{1,2,\dotsc,k\}.\label{eqn:feasible}
	\end{alignat}
\end{subequations}


\noindent Conditions \eqref{eqn:allpacked} and \eqref{eqn:nointersect} state the requirement that every element must be in exactly one of the $k$ subsets, while condition \eqref{eqn:feasible} specifies that each subset must be feasible. The set $\mathcal{F}$ is used to denote the set of all feasible subsets of elements in $\mathcal{I}$. The notion of feasibility is dependent on the specific constraint of the given problem.

One particular area of operational research involving grouping are packing problems. The classical one-dimensional bin-packing problem (BPP) requires a set of items of varying sizes to be packed into the fewest number of containers of fixed capacity. It can be seen that for this problem $\mathcal{F}$ contains all subsets of items whose total size does not cause the bin to be overfilled. Although seemingly simple by definition, the BPP is NP-hard, and is highly researched \intro{rewrite}. From the BPP stems a multitide of packing problems with various adaptations.

An interesting problem related to the BPP is the Trapezoid Packing Problem (TPP) initially investigated by Lewis et al.\cite{lewis2011}. In the roofing industry, trusses are to be cut from wooden boards so that the number of boards used is minimised. These trusses, however, are trapezoidal in shapre, which introduces the additional challenge of minimising the amount of triangular waste material between the trapezoids on each board by rotating and reordering the items.

Another problem is discussed by Garraffa et al.\cite{garraffa2016}, in which rectangular items are to be cut from strips of fixed length. During the cutting process, material is lost due to the type of machine used. The amount of these ``cut losses'' varies between different adjacent items on the strips. In this case, the task involves packing the items onto the fewest number of strips such that the sum of item lengths \emph{and} the sum of cut losses between adjacent items on each strip does not exceed the capacity of the strip.

Not only do these problems involve deciding which strip each item should be assigned to, but, unlike the BPP, they also consist of determining the order and orientation of the items on each strip.


Some problems require a solution $\mathcal{S}$ to be partitioned into exactly $k$ subsets, while others have the task of minimising the number of subsets $k$ required to partition the items provided the constraints are met. The latter problems are known as Minimum Grouping Problems (MGPs), named so by Lewis \cite{lewis2009}. A particular area of operational research relying on MGPs is packing problems. The classical one-dimensional bin-packing problem (BPP) requires a set of items to be packed into the fewest number of containers of a set capacity so that no container is overfilled. This problem is identified as an Order Independent Minimum Grouping Problem (OIMGP). In this paper, however, we will focus on another type of packing problem, Order Dependent Minimum Grouping Problems.

Consider the Constrained Ordering Problem (COP), as defined in Hawa et al. \cite{hawa2018}:
\begin{definition}
	\label{defn:cop}
	Let $\mathcal{M}$ be a multiset of unordered pairs, $\mathcal{M} = \{\{a_1, b_i\}, \{a_2, b_2\},\dotsc,\{a_n, b_n\}\}$, $a_i, b_i \in \mathbb{Z}^+$, and let $\mathcal{T}$ be an ordering of the elements of $\mathcal{M}$ such that each element is a tuple. Given a fixed value $\tau \in \mathbb{Z}^+$, the Constrained Ordering Problem (COP) consists of finding a solution $\mathcal{T}$ such that
	\begin{equation}
	\label{eqn:vsc}
	\emph{\textbf{rhs}}(i) + \emph{\textbf{lhs}}(i+1) \geq \tau \quad \forall \hspace{1mm} i \in \{1,2,..., n-1\},
	\end{equation}
	where \emph{\textbf{lhs}($i$)} and \emph{\textbf{rhs}($i$)} denote the left- and right-hand values of the $i$th tuple. The inequality is referred to as the \emph{vicinal sum constraint}.
\end{definition}

For example, given the COP instance $\mathcal{M} = \{\{1,2\}, \{1,6\}, \{2,3\}, \{2,4\}, \{3,5\}, \{4,5\}\}$, and a constraint value $\tau = 7$, a possible solution is $\mathcal{T} = \langle(1,6), (2,4), (3,5), (2,3), (4,5), (2,1)\rangle$. 

One specific application of the COP was seen in a strip-packing problem introduced as an open-combinatorial problem by Goulimis in 2004 \cite{goulimis2004}. A set $\mathcal{I}$ of $n$ rectangular cardboard items of equal height $H$ and varying widths $w_i \in \mathbb{Z}^+$ are to be packed on a strip from left to right. Each item $i \in \mathcal{I}$ is marked with two vertical lines, called score lines, in predetermined places. The distance between each score line and the edge of the item are score widths, $a_i, b_i \in \mathbb{Z}^+$. Once the items are packed onto the strip, a pair of knives on a bar simultaneously cut along the score lines of two adjacent items to aid the folding process. Due to the manner in which the knives are secured onto the bar, the knives must maintain a set distance from one another, a so-called ``minimum scoring distance'', which is approximately 70mm in industry.Therefore, in order for the knives to score all of the items in the correct locations, the distance between two score lines of adjacent items must exceed the minimum scoring distance. Hence, the problem involves packing the items onto the strip in such a way that the sum of all adjacent score widths exceeds the minimum scoring distance.\footnote{Note that the outermost score widths are not adjacent to any other items and do not need to abide by the vicinal sum constraint.} Figure~\ref{fig:itemsknife} shows how items are scored simultaneously.

\begin{figure}[H]	
	\centering
	\includestandalone[width=0.75\textwidth]{figures/itemsknife}
	\caption{Dimensions of an item $i \in \mathcal{I}$ in a regular orientation $(a_i, b_i)$, and an alignment of three items showing feasible and infeasible orderings.}	
	\label{fig:itemsknife}
\end{figure}


It follows that to find a feasible solution, the ordering \emph{and} the orientation of the items need to be decided. As there are $2^{n-1} n!$ distinct orderings of $n$ items, an increase in the problem size can easily lead to a combinatorial explosion. For this single strip problem, the widths of the items are disregarded, as it is assumed that the set of items will fit onto the given strip. Suppose now, that the strips provided have a fixed finite width (as is common in industy). We can then define the multi-strip version of the problem.

\begin{definition}
	\label{defn:scspp}
	Let $\mathcal{I}$ be a set of $n$ rectangular items of height $H$ with varying widths $w_i \in \mathbb{Z}^+$ and score widths $a_i, b_i \in \mathbb{Z}^+$ for each item $i \in \mathcal{I}$. Given a minimum scoring distance $\tau \in \mathbb{Z}^+$, the Score-Constrained Strip-Packing Problem (SCSPP) consists of finding the minimum number of strips of height $H$ and width $W$ required to pack all items in $\mathcal{I}$ such that the sum of every pair of adjacent score widths is greater than or equal to $\tau$ and no strip is overfilled.
\end{definition}

The SCSPP is an ODMGP, as not only must we determine which strip to pack each item onto, but also the order and orientation of the items within each strip. Thus, the BPP can be seen as a special case of the SCSPP when $\tau = 0$. Although items can be put through the machine to be scored individually, it takes longer and thus incurs extra costs.


In the next section, we will provide a brief overview of the polynomial-time algorithm used to solve the COP. Section~\ref{sec:scspp} will explain the difficulties associated with the SCSPP, and analyse bespoke heuristics. An evolutionary algorithm for the SCSPP is detailed in Section~\ref{sec:ea}, along with results from rigorous experiments.  

{\color{Orange}
\begin{itemize}[leftmargin=*]
	\item Lit review, Becker \cite{becker2015}, Lewis \cite{lewis2011} (Lewis TSP method), Hawa \cite{hawa2018}, cite Garraffa \cite{garraffa2016}.
	\idone{MGPs, cite Lewis \cite{lewis2009}, general formula.}
	\item ODMGPs, hard constraint.
	\idone{Formal definition COP, vicinal sum constraint.}
	\item Describe other problems using COP - TSP, 2 cities each state?
	\idone{Example instance $\mathcal{M}$ of COP and possible solution $\mathcal{T}$ using constraint value $\tau = 7$.}
	\idone{Description of subproblem, pack from left to right, minimum scoring distance, single strip problem.}
	\idone{Cite Goulimis \cite{goulimis2004}.}
	\idone{$a_i, b_i, w_i, \mathcal{I}, \mathcal{I}', W, H, \tau, |\mathcal{I}| = n$.}
	\idone{$\tau$ = 70mm approx in industry.}
	\item $(a_i, b_i)$, $(b_i, a_i)$ orientations (regular and rotated).
	\idone{Outermost score widths/elements ignored.}
	\idone{Need to decide order and orientation of items on strip.}
	\idone{$2^{n-1} n!$ distinct orderings, combinatorial explosion.}
	\item Show that the subproblem is equivalent to the COP, minimum scoring distance = VSC.
	\idone{COP/subproblem the strips have infinite width, what if finite width?}
	\idone{Formal defintion of SCSPP, multistrip problem.}
	\idone{Need to decide which strip to pack each item, and \emph{how}, i.e. what order and orientation should the items be in.}
	\idone{BPP special case of SCSPP with $\tau = 0$.}
	\idone{Items can be run through machine individually but extra time/cost.}
	\item Two phase approach, EA then postopt, Malaguti \cite{malaguti2008}.
	\idone{Call the two phase process EAX?}
	\item Polynomial-time algorithm for COP Hawa \cite{hawa2018}.
	\item Describe rest of paper/layout.
\end{itemize}
}

%--------------------------------------------------------------------------------------

\section{The Alternating Hamltonian Construction (AHC) algorithm}
\label{sec:ahc}
We begin by producing a graphical representation of the given instance $\mathcal{M}$ of the COP. The graph $G$ has a vertex set $V$ defined using one vertex for each element in $\mathcal{M}$ in non-decreasing order. Each vertex $v_i \in V$ is weighted with the value it represents. For simplicity, we shall refer to each value in $\mathcal{M}$ by its vertex on $G$.

In order to prevent executing the algorithm unnecessarily, we are able to perform a simple check to determine if a given instance is infeasible. Of the $2n$ values, suppose the smallest values $v_1$ and $v_2$ are placed on the end of the ordering. Clearly, if the next-smallest value $v_3$ and the largest value $v_{2n}$ do not meet the vicinal sum constraint, then there cannot exist a feasible ordering of all elements in $\mathcal{M}$.\footnote{A positive outcome from this test does not imply that a feasible solution exists for a given instance.}

If $\mathcal{M}$ has not been decided as infeasible, an extra pair of vertices is added to $G$, which have values equal to $\tau$. $G$ comprises two edge sets: $B$, which contains blue edges between vertices that are ``partners'' (that is, whose values make up an unordered pair in $\mathcal{M}$); and $R$, containing red edges between vertices that add up to $\geq \tau$ and are not partners. The extra pair of vertices, $v_{2n+1}$ and $v_{2n+2}$ can be seen to be dominating vertices, as their weighted values means they will be adjacent to every other vertex via an edge in $R$, and thus have degrees of $2n+1$.\footnote{Note that the dominating vertices $v_{2n+1}$ and $v_{2n+2}$ are partners.} Given the bijective function $p : V \to V$ that associates each vertex $v_i \in V$ with its partner $p(v_i)$, we can denote the set of edges between partners as $B = \{(v_i, p(v_i)) : v_i \in V\}$. Figure~\ref{fig:threshold} illustrates an example of the resulting graph $G = (V, B \cup R)$ produced from the instance provided in Section~\ref{sec:intro}. It can be seen that $|B| = n+1$, hence $B$ is a perfect matching. The graph has a noticeable pattern, with the degree of each vertex increasing in accordance with the weight of the vertices.

A Hamiltonian cycle in a graph $G$ is a cycle that visits every vertex of $G$ exactly once. A graph containing such a cycle is said to be Hamiltonian. From this, we define a specific type of Hamiltonian cycle:

\begin{definition}
	\label{defn:althamcycle}
	Let $G = (V, B \cup R)$ be a simple, undirected graph where each edge is a member of one of two sets, $B$ or $R$. $G$ contains an alternating Hamiltonian cycle if there exists a Hamiltonian cycle such that successive edges alternate between sets $B$ and $R$.
\end{definition}

Note that a red edge in $G$ shows two values from different unordered pairs that meet the vicinal sum constraint, and can be ordered adjacent to one another. Therefore, $R$ contains edges that represent to \emph{all} possible feasible pairings of values. It can be seen that an alternating Hamiltonain cycle in $G$ corresponds to a feasible ordering of the elements in $\mathcal{M}$, as the edge from $R$ depict the order of each tuple in $\mathcal{T}$ and the order of the values \emph{within} each tuple. The solution $\mathcal{T}$ must containg all elements from the problem instance $\mathcal{M}$, so all $n+1$ edges in $B$ must be present in the alternating Hamiltonian cycle. Thus, our task is to find a suitable set of edges $R' \subseteq R$ that, together with the edges in $B$, form an alternating Hamiltonian cycle in $G$. As $B$ is a perfect matching, it follows that $R'$ must also be a matching, else there will not be enough edges to form the cycle.

The dominating vertices are used to aid the construction of the alternating Hamiltonian cycle, as they are able to connect to the smallest vertices. Once an alternating Hamiltonian cycle has been produced, the dominating vertices and any incident edges are removed, leaving the smallest vertices as the end points on the path. These vertices correspond to the smallest values in the problem instances, which will be in the outermost positions in the solution $\mathcal{T}$.

Determining whether a graph is Hamiltonian is one of the well-known 21 NP-complete problems \cite{karp1972}. The problem of actually finding a Hamiltonian cycle is NP-hard. Consequently, the alternating Hamiltonian cycle problem is also NP-hard, as it is a generalisation of the Hamiltonian cycle problem \cite{haggkvist1977}. However, due to the manner in which graphs are created from instances of the COP, and the requirement that all edges in $B$ must be included, we are able to determine if an alternating Hamiltonian cycle exists, and produce a feasible solution if one does exist, in polynomial time \cite{hawa2018}.

The Maximum Cardinality Matching (MCM) algorithm is used to produce a matching $R'$ from $R$. MCM takes each vertex $v_1, v_2,\dotsc,v_{2n+2}$ and adds to $R'$ the edge from $R$ connecting $v_i$ to the highest-indexed vertex $v_j$ that is not incident to an edge in $R'$. Pairs of vertices incident to edges in $R'$ are said to be ``matched''. As with partners, the bijective function $m : V \to V$ associates with each vertex $v_i \in V$ its match, $m(v_i)$. This set can then be denoted as $R' = \{(v_i, m(v_i)): v_i \in V\}$. In the event that a vertex $v_i$ is not adjacent to any other vertex via an edge in $R$, the previous vertex $v_{i-1}$ can be rematched, provided 
\begin{enumerate*}[label={(\alph*)}]
	\item $i \neq 1$;
	\item $v_{i-1}$ has been matched; and
	\item $(v_{i-1}, p(v_i)) \in R$.
\end{enumerate*} 
Then, we simply set $m(v_i) = m(v_{i-1})$, and $m(v_{i-1}) = p(v_i)$.

If $R'$ does not contain $n+1$ edges, then no feasible solution exists. Otherwise, the subgraph $G'=(V, B \cup R')$ is a 2-regular graph consisting of cyclic components $C_1,C_2,...,C_l$, as show in Figure~\ref{fig:matching} and~\ref{fig:mps}. Clearly, if $l = 1$, then $G'$ is an alternating Hamiltonian cycle, and a solution has been found. In the case of $l > 1$, these components must be connected together to form a single alternating Hamiltonian cycle.

\begin{figure}[H]	
	\centering
	\begin{subfigure}[h]{0.3\textwidth}
		\includestandalone[width=\textwidth]{figures/threshold}
		\caption{}
		\label{fig:threshold}
	\end{subfigure} \hspace{5mm}
	\begin{subfigure}[h]{0.3\textwidth}
		\includestandalone[width=\textwidth]{figures/matching}
		\caption{}
		\label{fig:matching}
	\end{subfigure} \hspace{5mm}
	\begin{subfigure}[h]{0.25\textwidth}
		\includestandalone[width=\textwidth]{figures/mps}
		\caption{}
		\label{fig:mps}
	\end{subfigure}
	\caption{(a) $G = (V, B\cup R)$; (b) $G'=(V, B \cup R')$ produced after MCM; (c) $G'$ in planar form, where it is clear that $G'$ comprises $l = 3$ cyclic components.}
	\label{fig:mcm}
\end{figure}

Recall that an edge in a graph is a \emph{bridge} if the removal of the edge increases the number of components of the graph. In order to connect the multiple cyclic components of $G'$, we must select edges from $R \backslash R'$ that are able to act as bridges between the components. To find such edges, the Bridge Recognition (BR) algorithm is executed.

BR searches for an edge whose lower-indexed vertex is adjacent to the next edge's higher-indexed vertex, and that is not in the same component of $G'$ as the next edge. This edge starts the set $R_1$, and succeeding edges are added to $R_1$ provided the conditions hold and the next edge is not in the same component as any of the edges in $R_1$. Once there are no more valid edges to add to $R_1$, BR searches through the list to find another edge to start a set $R_2$. BR continues creating these sets until the penultimate edge has been reached. If BR is unable to produce a set, then clearly no solution exists. Else, if there exists a set $R_i$ that has a cardinality of $l$, then the components of $G'$ can be connected by adding to $R'$, for each edge in $R_i$, the edge from $R \backslash R'$ incident to its lower-indexed vertex and the higher-indexed vertex of the next edge (for the last edge, take the first edge in $R_i$ to be the next edge). The edges in $R_i$ that appear in $R'$ are then removed, resulting in $n+1$ edges in $R'$ that form an alternating Hamiltonian cycle on $G'$ with the edges in $B$. An example of this is shown in Figure~\ref{fig:br}, where BR has produced a single set $R_1 = \{\{v_3, v_{12}\},\{v_4, v_{11}\}, \{v_5, v_{10}\}\}$.


In some cases, more than one set $R_i$ is needed to connect the components. Two sets $R_i$ and $R_j$ are said to ``overlap'' if they both contain exactly one edge from the same component of $G'$. A Modified Bridge Recognition (MBR) algorithm finds a collection $\mathcal{R}^*$ of overlapping sets. It initially operates in a similar fashion to BR, creating a set $R^{*}_1$ using the same conditions and adding it to $\mathcal{R}^*$. However, once no more edges can be added to $R^{*}_1$, the edges in $R^{*}_1$ are removed from the list. MBR restarts the search from the beginning of the list to find edges for a new set $R^{*}_2$, with the additional condition that $R^{*}_2$ must overlap with $R^{*}_1$. This process is repeated, creating sets that overlap with ones in $\mathcal{R}^*$. If at any point $\mathcal{R}^*$ contains at least one edge from every component in $G'$, the procedure immediately terminates. The connecting procedure is then applied to each set $R^{*}_i \in \mathcal{R}^*$, combining all components of $G'$ to form a alternating Hamiltonian cycle. If the penultimate edge is reached and $\mathcal{R}^*$ does not contain sufficient overlapping sets, it can be said with absolute certainty that there does not exist a feasible solution $\mathcal{T}$ for the corresponding COP instance $\mathcal{M}$ \cite{hawa2018}.

\begin{figure}[H]	
	\centering
	\begin{subfigure}[h]{0.23\textwidth}
		\includestandalone[width=\textwidth]{figures/mpsconnect}
		%\caption{}
		\label{fig:mpsconnect}
	\end{subfigure} \hspace{5mm} %
	\begin{subfigure}[h]{0.23\textwidth}
		\includestandalone[width=\textwidth]{figures/mpscycle}
		% \caption{}
		\label{fig:mpscycle}
	\end{subfigure} \hspace{5mm}
	\begin{subfigure}[h]{0.23\textwidth}
		\includestandalone[width=\textwidth]{figures/mpspath}
		% \caption{}
		\label{fig:mpspath}
	\end{subfigure}
	\caption{Bridge Recognition (BR) process of connecting multiple components to produce a single alternating Hamiltonian cycle that corresponds to a solution $\mathcal{T}$. \ahc{using set $R_1 = \{\{v_3, v_{12}\}, \{v_4, v_{11}\}, \{v_5, v_{10}\}\}$, dom vertices removed to form path, values in order}}
	\label{fig:br}
\end{figure}

{\color{myLightBlue}
\begin{itemize}[leftmargin=*]
	\ialert{How does this method differ from Becker's?}
	\item Exact Polynomial-time algorithm for COP Becker \cite{becker2015} Hawa \cite{hawa2018}.
	\idone{Model instance graphically, graph $G$ with $V = \{v_1, ...v_{2n}\}$ vertices, one for each value in $\mathcal{M}$ in non-decreasing order.}
	\idone{Preliminary checks using elements, explain, speed.}
	\item Cite Lewis \cite{lewis2011} for preliminary checks.
	\idone{Add two dominating vertices, have value equal to $\tau$, therefore $G$ has $2n+2$ vertices.}
	\idone{Dom vertices will be removed at the end.}
	\idone{degree $2n+1$.}
	\idone{$B$, blue edges between ``partners'' (values that make up a pair in $\mathcal{M}$)}.
	\idone{$|B| = n+1$, perfect matching.}
	\idone{Footnote dom vertices are partners.}
	\idone{Bijective function partners, $p : V \to V$, $p(v_i) = v_j$.}
	\idone{$R$, red edges between vertices whose values add up to $\tau$/meet VSC and are not partners.}
	\idone{Given the bijective function $p:V \to V$ that associates each vertex $v_i \in V$ with its partner $p(v_i)$, we can denote the set of blue edges as $B = \{(v_i, p(v_i)) : v_i \in V\}$.}  
	\idone{Then we have a graph $G = (V, B \cup R)$ (see figure).}
	\idone{Higher-indexed vertices have larger degrees.}
	\idone{Define Ham cycle, formal definition alt Ham cycle.}
	\idone{$R$ = all possible pairings of values.}
	\idone{$B$ cannot be altered, all edges must remain, as each edge represents a pair of values.}
	\idone{Therefore aim is to find set of edges from $R$ that forms alt Ham cycle with $B$.}
	\idone{Ham cycle NP-complete, Karp \cite{karp1972}, alt Ham generalises Ham cycle, Haggkvist \cite{haggkvist1977} proposition, special structure of graphs means can solve in polynomial-time.}
	\idone{MCM - match each vertex with largest possible vertex, create set $R'$.}
	\item Cite Mahadev \cite{mahadev1994}.
	\idone{Explain ``matched'', bijective function.}
	\idone{Can denote $R'$ as $R' = \{(v_i, m(v_i)) : v_i \in V\}$.}
	\idone{Swap of partners.}
	\idone{If $|R'| < n+1$, no solution exists, not enough edges to form cycle, end. Else if $|R'| = n+1$, i.e. matching, then $G' = (V, B \cup R')$ is 2-reg graph, consists of cycles $C_1,...,C_l$.}
	\idone{If $l = 1$, then $G'$ is alt ham cycle, solution found, end.}
	\idone{Else we need to find edges from $R\backslash R'$ that can act as bridges between the components and join them together into a single cycle.}
	\idone{Use BR to find these edges. List edges in order, go through to find edges that meet specific conditions. Continue until penultimate edge reached.} 
	\idone{BR produces sets $R_1, R_2,...$.}
	\idone{If no sets produced, no solution exists, end. Else if $\exists$ set such that $|R_i| = l$, use connecting procedure to join components together, solution found, end.}
	\idone{Else multiple sets need to be used, run MBR to find two or more sets that overlap correctly. If collection $\mathcal{R}^*$ found, connecting procedure on all sets in collection, solution found, end. Else, no solution exists, end.}
	\item Guaranteed to find solution, if one exists, in $O(n^2)$ time.
	\item MBR types, check that Beckers method is redundant.
	\item This is called the Alternating Hamiltonian Construction (AHC) algorithm.
	\item BR sorts edges of $R'$.
\end{itemize}
}

%--------------------------------------------------------------------------------------

\section{Heuristics for the SCSPP}
\label{sec:scspp}
A feasible solution for the SCSPP is represented by the set $\mathcal{S} = \{S_1, S_2, ..., S_k\}$ such that
\begin{subequations}
	\begin{alignat}{2}
	\bigcup\nolimits_{i=1}^{k} S_i &= \mathcal{I}, & \label{eqn:packall}\\[3pt]
	S_i \cap S_j &= \emptyset &\quad &\forall \hspace{1mm} i, j \in \{1,2,\dotsc,k\}, \hspace{1mm} i \neq j, \label{eqn:nooverlap} \\[3pt]
	\sum\nolimits_{i=1}^{|S_j|}w_i &\leq W &\quad &\forall \hspace{1mm} S_j \in \mathcal{S}, \label{eqn:capacity} \\[3pt]
	\textup{\textbf{rhs}}(i) + \textup{\textbf{lhs}}(i+1) &\geq \tau &\quad &\forall \hspace{1mm} i \in \{1, 2,\dotsc,|S_j|-1\}, \hspace{1mm} \forall \hspace{1mm} S_j \in \mathcal{S}. \label{eqn:vscstrip}
	\end{alignat}
\end{subequations}



\noindent As stated in Definition \ref{defn:scspp}, the aim is to minimise $k$. An optimal solution for the SCSPP is a solution consisting of the fewest number of strips $k$ required to feasibly pack all items in $\mathcal{I}$. A basic lower bound for $k$ is the theorectical minimum, $t = \ceil{\sum_{i=1}^{n} w_i / W}$ \cite{martello1990l}. 

Equations \eqref{eqn:packall}-- \eqref{eqn:capacity} are the necessary conditions for the BPP. Although the BPP is simple by definition, finding solutions that meet all conditions can be difficult, and given large instances an exact solution may be impossible to find in a reasonable amount of time. One of the simplest and most well-known heuristics is the First-Fit (FF) heuristic, a greedy online algorithm that packs each item, given in some arbitrary order, into the lowest-indexed bin such that the capacity of the bin is not exceed, opening a new bin when required. It is known that there always exists at least one ordering of the items such that FF produces an optimal solution \cite{lewis2009}. An improvement on FF yields the First-Fit Decreasing (FFD) heuristic, which initially sorts the items in non-decreasing order of size. In 1973, Johnson \cite{johnson1973} showed that FFD is guaranteed to return a solution that uses no more than $\frac{11}{9}k + 4$ bins. More recently, Dosa \cite{dosa2007} has proven that the worst case for FFD is in fact $\frac{11}{9}k + \frac{6}{9}$, and that this bound is tight. Due to the initial sorting of the items, the time complexity of FFD is $O(n \lg n)$.

It can be seen that $t$ will not perform as accurately for the SCSPP as it does for the BPP. Consider a set of $n$ items in which the largest score width $b_i < \tau/2$. There are no pairs of items that can be packed alongside one another feasibly, thus $\mathcal{S}$ will require $n$ strips. The theoretical minimum does not consider the effect of the minimum scoring distance on the feasibility of the solution. 

The minimum scoring distance also introduces differences in solutions for the BPP and SCSPP. The obvious difference is that of the ordering and orientation of the items on the strips: unimportant in the BPP, but vital for the feasibility of a solution for the SCSPP. Another distinction arises when attempting to modify solutions. Again, a solution for the BPP remains feasible when an item is removed or a new item is added to a strip (provided the strip can accommodate said item), whereas for the SCSPP this may render a solution infeasible, as the new pairings of score widths may not abide by the vicinal sum constraint.

As the SCSPP generalises the BPP, it follows that the SCSPP is also NP-hard. Assuming $P \neq NP$, we cannot hope to find an optimal solution for all instances of the SCSPP in polynomial time. The simplest methods to implement are heuristics, which trade optimality for speed.

As the SCSPP is a relatively new problem, little research has been produced. Some basic heuristics were introduced in Hawa et al. \cite{hawa2018}, two of which are based on the well-known first-fit decreasing (FFD) heuristics. The first, named the Modified First-Fit Decreasing (MFFD) heuristic, performs in the same fashion as FFD, with the extra condition that an item can only be packed onto the end of a strip if the score width on the end of the strip and one of the score widths on the item meet the vicinal sum constraint. An improvement on MFFD is their second heuristic, MFFD$^+$, which incorporates AHC. Rather than attempting to pack each item onto the end of the strips, MFFD$^+$ calls upon AHC to find a feasible ordering of all items on a given strip that includes the item to be packed.\footnote{If an item is the first to be packed on a strip, it is placed in a regular orientation (that is, the smaller score width is on the left-hand side).} Clearly, MFFD$^+$ is the superior of the two, as the application of AHC guarantees that a feasible ordering will be found if it exists. The limitation on MFFD of only packing items on the end has the potential to increase the number of strips being used in a final solution unnecessarily. Figure~\ref{fig:mffdvsmffdp} illustrates how MFFD$^+$ is able to find a feasible arrangement of items which cannot be found using MFFD.

\begin{figure}[H]	
	\centering
	\includestandalone[width=0.85\textwidth]{figures/strips}
	\caption{Example instance of a subproblem with $\tau = 70$. Using MFFD, the constraint is not fulfilled in either orientation, however MFFD$^+$ is able to find a feasible arrangement.}	
	\label{fig:mffdvsmffdp}
\end{figure}

\subsection{Heuristics}
\label{sub:heuristics}

{\color{Rhodamine}
\begin{itemize}[leftmargin=*]
	\idone{Feasible solution $\mathcal{S} = \{S_1,...,S_k\}$ and four conditions.}
	\idone{SCSPP at least as hard as BPP, NP-hard (SCSPP generalises BPP, assuming $P \neq NP$).}
	\idone{Cannot find solution in reasonable time, therefore use heuristics, near optimal solutions faster.}
	\item Lit review, heuristics used for BPP/SPP, FFD, BFD etc., how do these work with SCSPP (or ODMGPs in general).
	\idone{Optimal solution requires fewest number of strips $k$ to pack all items.}
	\idone{Lower bound for $k$ is theoretical minimum $t = \ceil*{\sum_{i=1}^{n}w_i / W}$.}
	\idone{Lowerbound cite Martello \cite{martello1990l}.}
	\idone{$t$ not accurate for SCSPP, doesn't take into account $\tau$, if $\tau >$ 2x largest score width then $n$ strips required, one for each item, regardless of item widths or strip width $W$.}
	\item May find optimal solution without knowing, as optimal number of strips for a given problem instance of the SCSPP may be greater than $t$.
	\item Can we show a solution is optimal? If not, why?
	\idone{Differences BPP and SCSPP: (1) Importance of order and orientation of items; (2) Feasibility of strips when adding/removing/rearranging items.}
	\item $\mathcal{F}$ denotes the set of all subsets $\mathcal{I}' \subseteq \mathcal{I}$ of items that can be feasibly packed onto a single strip, i.e. $\sum_{i \in S} w_i \leq W$ and VSC met.
	\idone{Heuristics for SCSPP Hawa \cite{hawa2018}.} 
	\idone{Our implementation of AHC in MFFD$^+$ has the preliminary check, previous paper does not.}
	\idone{MFFD - FFD but only place item if score width on end of strip meets VSC with a score width on the item (check both orientations) - operates in the same way as FFD, except additional step of checking that VSC is met with one of the score widths of the item and the right-most score width on the strip, i.e. check that $S \cup \{i\} \in \mathcal{F}$.}
	\idone{MFFD$^+$ - FFD, incorporates AHC, instead of checking VSC on end of strip, run AHC using all items on strip and current item. If item fits on strip, run AHC on items on strip and current item. If solution found, replace current arrangement of items on strip with arrangement found by AHC including new item, else move on to next strip.}
	\idone{If item starts new strip, pack item in regular orientation, i.e. $(a_i, b_i)$, smaller score width on left-hand side.}
	\idone{ MFFD$^+$ can find solution for subset of items, rearrange all items, MFFD cannot, only place items on end.}
	\idone{MFFD may require extra strips for items even though feasible ordering exists using AHC.}
	\item MFFD$^+$ slower, could be a different ordering of items works better (rather than items in decreasing order of widths), one item at a time might not find feasible ordering, may be that feasible ordering exists when packing multiple items simultaneously.
	\item Fast greedy heuristics not as good, other methods superior.
	\item Therefore use evolutionary algorithm (lead on to next section).
\end{itemize}
}


\subsection{Experimental Results - Heuristics}
\label{sub:expheuristics}
For our experiments, we produced two different types of instances: ``artificial'' instances, which contain items of varying widths and score widths; and ``real'' instances, which have multiple items of the same dimension. For each type 1000 instances were generated using sets of 100 and 500 items, giving a total of 4000 problem instances. For all instances, the minimum scoring distance $\tau$ was set to 70mm - the industry standard. All items have widths $w_i \in [150,1000]$ and score widths $a_i, b_i \in [1,70]$ selected uniform randomly, and equal height $H=1$. To compare our heuristics, we use two different strips widths, 2500 and 5000.

\begin{table}[h!]
	\centering
\caption{MFFD vs MFFD$^+$}
\begin{threeparttable}
\begin{tabular}{cccccccccccc}\toprule
	& & & \multicolumn{4}{c}{MFFD} &\phantom{a}& \multicolumn{4}{c}{MFFD$^+$}\\
	\cmidrule{4-7} \cmidrule{9-12}
	Instance & $W$ & $t$ & $|\mathcal{S}|$\tnote{1} & $\# t$ & $q$ & $f(\mathcal{S})$ && $|\mathcal{S}|$ & $\# t$ & $q$ & $f(\mathcal{S})$\\ \midrule	
	a,100 & 2500 & 23.323 & 30.754 & 0 & 1.320 & 0.686 && 28.457 & 26 & 1.221 & 0.771 \\
	a,100 & 5000 & 11.922 & 23.583 & 0 & 1.982 & 0.412 && 19.881 & 7 & 1.670 & 0.543  \\
	\midrule
	a,500 & 2500 & 114.942 & 140.206 & 0 & 1.220 & 0.781 && 132.647 & 0 & 1.154 & 0.842 \\
	a,500 & 5000 & 57.722 & 103.209 & 0 & 1.789 & 0.499 && 89.544 & 0 & 1.552 & 0.609 \\
	\midrule
	\midrule
	r,100 & 2500 & 23.473 & 37.069 & 5 & 1.600 & 0.549 && 35.419 & 16 & 1.523 & 0.597 \\
	r,100 & 5000 & 11.981 & 32.348 & 1 & 2.731 & 0.288 && 29.611 & 5 & 2.497 & 0.347 \\
	\midrule
	r,500 & 2500 & 115.239 & 184.106 & 0 & 1.612 & 0.552 && 177.249 & 0 & 1.551 & 0.593 \\
	r,500 & 5000 & 57.865 & 163.819 & 0 & 2.860 & 0.279 && 153.416 & 0 & 2.678 & 0.322 \\
	\bottomrule
\end{tabular}
\begin{tablenotes}
	\item[1] Mean from 1000 instances
\end{tablenotes}	
\end{threeparttable}	
\label{table:MFFD}
\end{table}

\begin{table}[h!]
\centering
\caption{average number of items per strip - MFFD vs MFFD$^+$}
	\begin{tabular}{ccccc}\toprule
		Instance & $W$ & items/lb & MFFD & MFFD$^+$ \\ \midrule	
		a,100 & 2500 & 4.288 & 3.252 & 3.514 \\
		a,100 & 5000 & 8.388 & 4.240 & 5.030 \\
		\midrule
		a,500 & 2500 & 4.350 & 3.566 & 3.769 \\
		a,500 & 5000 & 8.662 & 4.845 & 5.584 \\
		\midrule
		\midrule
		r,100 & 2500 & 4.260 & 2.698 & 2.823 \\
		r,100 & 5000 & 8.347 & 3.091 & 3.377 \\
		\midrule
		r,500 & 2500 & 4.339 & 2.716 & 2.821 \\
		r,500 & 5000 & 8.641 & 3.052 & 3.259 \\
		\bottomrule
	\end{tabular}	
\end{table}

{\color{Rhodamine}
\begin{itemize}[leftmargin=*]
	\item Time it takes to run heuristics.
	\item Tables of comparisons.
	\item State that there are 20 types on average for real instances (no longer in table).
\end{itemize}
}

%--------------------------------------------------------------------------------------

\section{Evolutionary Algorithm}
\label{sec:ea}
An evolutionary algorithm (EA) is a metaheuristics optimisation algorithm inspired by the natural evolutionary process. Candidate solutions to the problem form the initial population, and procedures emulating selection, reproduction, recombination and mutation are used to create the next generation of solutions. This iterated process results in the evolution of the solutions. Each solution is evaluated based on a given critera, and individuals which are more suited to the environment are given more oppportunity to breed, while those which are less so are eliminated.


Throughout the EA we maintain two sets, $\mathcal{A}$ and $\mathcal{B}$, containing subsets of items that AHC has determined produce feasible or infeasible orderings, respectively. When an instance of the subproblem occurs, these sets are searched before calling AHC; hence AHC is executed at most once for each distinct subset of items.

{\color{OrangeRed}
\begin{itemize}[leftmargin=*]
	\item Why use an EA? Lit review of EAs in BPP problems, benefits (repeated multiple times, best characteristics of strips/solutions).
	\idone{Whenever subproblem occurs, AHC will be used.}
	\idone{Sets $\mathcal{A}$ and $\mathcal{B}$, subsets of items that produce feasible/infeasible orderings determined by AHC. Search these sets before calling AHC, therefore AHC used at most once for each distinct subset of items $\mathcal{I}' \subseteq \mathcal{I}$.}
	\item Feasible solution $\mathcal{S}$ means solution abides by all constraints.
\end{itemize}
}


\subsection{Crossover Operator}
\label{sub:xover}
A crossover operator within an EA is used to generate new solutions from an existing population. This is done by taking two parent solutions, $\mathcal{S}_1$ and $\mathcal{S}_2$, and combining them to create a new offspring solution. The operator determines which characteristics from each parent should be inherited by the offspring. Thus, the operator attempts to retain the best elements of each parent, with the aim of producing a superior offspring. As described in Section~\ref{sec:scspp}, we cannot simply copy individual items from each parent into the offspring, as it may result in an infeasible solution. Our crossover operators are therefore designed to ensure offspring feasibility.

The first operator is based on the grouping genetic algorithm (GGA) of Falkenauer \cite{falkenauer1992}. The strips of the second parent solution $\mathcal{S}_2$ are permuted, and two strips $S_i$ and $S_j$ from $\mathcal{S}_2$ are selected randomly (where $1 \leq i < j \leq |\mathcal{S}_2|$). These strips, along with all strips in between, are inserted into the offspring solution $\mathcal{S}$. The operator then adds to the offspring all strips from $\mathcal{S}_1$ that do not contain items already present in the offspring. Note that the strips chosen from $\mathcal{S}_2$ cannot both be the outermost strips, that is, GGA cannot choose $i = 1$ \emph{and} $j = |\mathcal{S}_2|$. This is because doing so would result in all strips from $\mathcal{S}_2$ being copied into the offspring, preventing the addition of any strips from $\mathcal{S}_1$.

%Any items that are not in $\mathcal{S}$ are used to created a feasible partial solution $\mathcal{S}'$ using MFFD$^+$. Local search is then used on $\mathcal{S}$ and $\mathcal{S}'$ to produce a full offspring solution.

The next operator, \ea{GPX'}, is analogous to that of Quiroz-Castellanos et al. \cite{quiroz2015}. Starting with the parent solution containing the fullest strip,\footnote{For both \ea{GPX'} and \ea{GPN}, in the event that both parents contain the fullest strip or the strip containing the most items, the starting parent solution is chosen at random.} the operator inserts this strip into the offspring $\mathcal{S}$, and strips containing items in $\mathcal{S}$ are removed from the other parent. Then, the operator selects the fullest strip from the modified parent, and removes strips from the first parent. GPX' repeats this process, alternating between parents, until $min (|\mathcal{S}_1|,|\mathcal{S}_2|) - 1$ strips have been added to the offspring.

Our final operator, \ea{GPN}, performs in the same manner as \alert{GPX'}, instead selecting strips containing the most items. This method aims to choose strips containing items that are harder to pack along with other items.

In order to maintain feasibility, our operators remove entire strips containing duplicate items, rather than individual items. These strips may also contain items that are not present in the offspring solution. Consequently, on completion of the crossover, the offspring solution $\mathcal{S}$ may not contain all $n$ items, and is therefore not yet a full solution. To rectify this, MFFD$^+$ is applied using the missing items to form a partial solution $\mathcal{S}_Y$. The partial offspring solution $\mathcal{S}$ and $\mathcal{S}_Y$ are then used as input into a local search procedure to create a full feasible offspring solution.

{\color{OrangeRed}
\begin{itemize}[leftmargin=*]
	\item Purpose of recombination/crossover, select best characteristics of each parent solution to form offspring. 
	\item Prevent duplicate items.
	\item Note the differences between BPP and SCSPP, cannot simply remove individual items from strips, may cause the arrangement of remaining items to become infeasible (VSC not met between items)- hence why GPX cannot be used \cite{lewis2017}
	\idone{GGA Falkenauer \cite{falkenauer1992}, permute strips of $\mathcal{S}_2$, select two strips, take all strips between and including these strips and put into offspring solution $\mathcal{S}$. Add from $\mathcal{S}_1$ strips that do not contain items already in offspring. Note, choose strips $1 \leq i < j \leq |\mathcal{S}_2|$ \textbf{and} cannot have $i = 1 \land j = |\mathcal{S}_2|$ unlike in Rhyd paper - ensures that at least 2 strips from $\mathcal{S}_2$ are in offspring, and prevents all strips from $\mathcal{S}_2$ from being selected, as this would mean that all strips from $\mathcal{S}_1$ would be deleted from the offspring, and so offspring will not have strips from both parents. Ensures that offspring has characteristics from both parents.}
	\idone{GPX', Quiroz \cite{quiroz2015} (check) - Alternate between parent solutions, add fullest strip to offspring, delete strips from other parent containing items in offspring. Continue until $min(|\mathcal{S}_1|,|\mathcal{S}_2|)-1$ strips in offspring. Initially, if both parents have fullest strip, break ties randomly.}
	\idone{GPN - Operates in the same manner as GPX', except chose strip containing the most items.} 
	\idone{Initially, if both parents have strip containing same number of max items, choose the parent whose strip is the fullest. If equal for both strips, choose randomly.}
	\item What does each xOver aim to do? Prevent duplicates (by deleting strips from other parent).
	\idone{Missing items, apply MFFD$^+$ to produce partial solution $\mathcal{S}_Y$, then apply Local search (described in next section) on offspring and $\mathcal{S}_Y$ to produce full offspring $\mathcal{S}$}
	\idone{Many missing items in comparison to BPP as cannot delete individual items due to VSC, have to delete entire strips, could contain items not yet in offspring.}
\end{itemize}
}


\subsection{Local Search}
\label{sub:localsearch}
Our local search method takes in two feasible partial solutions, $\mathcal{S}_X$ and $\mathcal{S}_Y$, permutes the strips of both, and then attempts to move items between the two solutions in four stages: 
\begin{enumerate*}[label={(\roman*)}]
	\item swapping a pair of items from a strip in $\mathcal{S}_X$ with a pair of items from a strip in $\mathcal{S}_Y$;\label{item:pairpair}
	\item swapping a pair of items from a strip in $\mathcal{S}_X$ with an individual item from a strip in $\mathcal{S}_Y$;\label{item:pairsin}
	\item swapping individual items from strips in $\mathcal{S}_X$ and $\mathcal{S}_Y$;\label{item:sinsin} and
	\item moving an item from a strip in $\mathcal{S}_Y$ to a strip in $\mathcal{S}_X$.\label{item:movesin}
\end{enumerate*} 
During stages \ref{item:pairpair}--\ref{item:sinsin}, the width of the item(s) from $\mathcal{S}_Y$ must exceed the width of the item(s) from $\mathcal{S}_X$. Once a swap or move has been perfomed, the procedure immediately moves on to the next stage. This method is repeated until all four stages have been executed in succession with no changes to $\mathcal{S}_X$ or $\mathcal{S}_Y$. Then, MFFD$^+$ is applied to any items remaining in $\mathcal{S}_Y$, generating a new feasible partial solution $\mathcal{S}_Y'$. The strips in $\mathcal{S}_Y'$, along with the strips in $\mathcal{S}_X$, are inserted into $\mathcal{S}$ to form a full feasible solution.

This method is based on the dominance criterion of Martello and Toth \cite{martello1990l}: if a strip $S_1$ \emph{dominates} a strip $S_2$, then a solution containing $S_1$ will have no more strips than a solution containing $S_2$. The local search procedure is in fact a local search for dominating strips. By moving larger items into $\mathcal{S}_X$, the ``fullness'' of the strips increase, whilst the number of items per strip is maintained or decreases, improving the quality of the strips in $\mathcal{S}_X$. Simultaneously, items moved into $\mathcal{S}_Y$ are smaller, and therefore easier to repack onto strips in $\mathcal{S}_X$ during stage~\ref{item:movesin}. Variations of this method can be seen in \cite{falkenauer1996}, \cite{levine2004}, \cite{lewis2009}, \cite{lewis2017}, however the addition of the vicinal sum constraint results in fewer changes than seen in these previous implementations. By iterating the stages, we create numerous distinct subsets of items on the strips, generating more possibilities for feasible orderings of items.

{\color{OrangeRed}
\begin{itemize}[leftmargin=*]
	\idone{Purpose of local search, takes two partial solutions $\mathcal{S}_X$ and $\mathcal{S}_Y$.}
	\idone{Initially permute strips.}
	\idone{4 stages, 3 swap, 1 move. width of items from $\mathcal{S}_X$ must be less than width of items from $\mathcal{S}_Y$ in first three stages.}
	\idone{Moves smaller items into $\mathcal{S}_Y$, larger items into $\mathcal{S}_X$.}
	\idone{If swap/move performed, move onto next stage. Repeat until no changes to either partial solution.}
	\idone{MFFD$^+$ applied on items in $\mathcal{S}_Y$ to produce partial solution $\mathcal{S}_Y'$. Then strips from $\mathcal{S}_X$ and $\mathcal{S}_Y'$ inserted into $\mathcal{S}$ (this is not necessarily offspring).}
	\idone{Based on dominance criterion of Martello and Toth \cite{martello1990l}.}
	\idone{If strip $S_1$ dominates $S_2$, the a solution using $S_1$ will have no more strips than a solution using $S_2$.}
	\idone{Aim - increase fullness of strips in $\mathcal{S}_X$ while maintaining or decreasing number of items on strips.}
	\idone{Moves smaller items into $\mathcal{S}_Y$, easier to repack in stage (4).}
	\idone{Variations of procedure seen in Falkenauer \cite{falkenauer1996}, Lewis \cite{lewis2009} \cite{lewis2017}, Levine \cite{levine2004}.}
	\idone{VSC makes swaps/moves more difficult, this means local search takes longer, fewer swaps than seen in \cite{lewis2009}, \cite{lewis2017}, \cite{levine2004}, \cite{falkenauer1996} (check).}
	\idone{Repeating process produces different combinations of items, more possibilities to find feasible ordering.}
	\item Well-filled strips with larger items preferable over less-filled strips with smaller items (Levine \cite{levine2004}).
\end{itemize}
}


\subsection{EA Process}
\label{sub:eaframework}
The algorithm begins by producing candidate solutions for the initial population, one using MFFD$^+$, the rest using MFFR$^+$ (that, is, the same method as MFFD$^+$ with the items in a random order). These solutions are mutated before being inserted into the population. Mutation of a candidate solution $\mathcal{S}$ involves permuting the strips, and inserting a random number of strips from $\mathcal{S}$ into a set $\mathcal{S}_X$, and the rest into a set $\mathcal{S}_Y$. Local search is then executed using these two partial solutions to produce a full solution, which is reinserted into $\mathcal{S}$. 

An iteration of the EA involves selecting two parent solutions, $\mathcal{S}_1$ and $\mathcal{S}_2$, from the population at random, applying a crossover operator to produce an offspring solution $\mathcal{S}$, then mutating this offspring before replacing the least fit of the two parents in the population.

A fitness function is used to calculate a fitness value to determine the quality of a solution, as opposed to simply relying on the number of strips within the solution. The reason for this is twofold: firstly, given two candidate solutions of equal size, it is impossible to determine the better solution based on the number of strips alone. Secondly, we note that the quality of a solution not only depends on the number of strips used, but \emph{how} the items are packed onto the strip. Recall that strips that are ``fuller'' are preferrable over less filled strips, even if they contain more items. Thus, we consider a strip whose capacity is taken advantage of to be a ``better packed'' strip, reducing the amount of waste material. This may result in a strip in the solution that is nearly empty, which is beneficial as it allows further items to be packed, or the residual material could be used for other means. This type of packing is desirable over a packing of strips that are only half full, requiring more strips than necessary to pack all of the items. 

We therefore make use of the following function to calculate the fitness of a solution $\mathcal{S}$:

\begin{equation}
	f(\mathcal{S}) = \frac{\sum_{S \in \mathcal{S}} (A(S)/W)^2}{|\mathcal{S}|}
\end{equation}
\noindent where $A(S) = \sum_{i \in S} w_i$ is the total width of all items on a strip $S$. This function produces a fitness value between 0 and 1. The higher the fitness, the better the quality of the packing of items in the solution.

{\color{OrangeRed}
\begin{itemize}[leftmargin=*]
	\idone{Create candidate solutions for initial population, one solution using MFFD$^+$, the others using MFFR$^+$ (items sorted in random order as opposed to decreasing order of widths), each solution is mutated before being inserted into the population.}
	\idone{Each iteration of EA, two parent solutions $\mathcal{S}_1$ and $\mathcal{S}_2$ are chosen from the population at random, crossover operator used to create single offspring solution $\mathcal{S}$, which is then mutated before replacing the least fit parent solution in the population (breaking ties randomly).}
	\idone{Fitness function $f(\mathcal{S}) = \frac{\sum_{S \in \mathcal{S}} (A(S)/W)^2}{|\mathcal{S}|}$ \cite{falkenauer1992}.}
	\idone{$A(S) = \sum_{i \in S} w_i$ - ``fullness''/total width of all items on strip $S$}
	\idone{value between 0 and 1, closer to 1 = better packing.}
	\idone{Although two solutions $\mathcal{S}_1$ and $\mathcal{S}_2$ may contain the same number of strips/have the same size, fitness value identifies which solution contains a better packing of the items - distinguish between two solutions of the same size.}
	\idone{Not only considering how many strips required to pack all items, but how those items are packed onto the strips (optimise how the strips are packed).}
	\idone{Better packed strips means full capacity of strip is taken advantage of, reduce waste material on strips, plus nearly empty strips can be used to accommodate more items, or waste material can be reused.}
	\idone{If the strips are packed well, fewer strips required, else if strips are not packed well, extra strips required to pack items that cannot be packed onto strips already being used.}
	\item Take into account vicinal sum constraint - there may be two strips that are roughly equally filled, however even though it may seem that the items could be shuffled so that more are on one strip (thus a better packing), it may not be possible due to the constraint - not taken into account in other applications of this fitness value, however will still use this fitness value as our aim is to produce the best packing possible given the constraint.
\end{itemize}
}


\subsection{Experimental Results - EA}
\label{sub:expea}

To allow for a fair comparison with the heuristics in Section~\ref{sec:scspp}, we used the same four sets of problem instances for the EA. Each of these four sets is used with six different combinations of crossover operators and strip widths. An initial population of 25 candidate solutions is fixed for all experiments. The EA is set to execute for 300 seconds. Table~\ref{table:ea} shows the output from our experiments.

\begin{table}[h!]
	\centering
	\caption{EA comparisons}
	\begin{tabular}{cccccccccccc}\toprule
		& & & &\multicolumn{2}{c}{GGA} &\phantom{a}& \multicolumn{2}{c}{GPX'} &\phantom{a}& \multicolumn{2}{c}{GPN}\\
		\cmidrule{5-6} \cmidrule{8-9} \cmidrule{11-12}
		Instance & $W$ & $t$ && $|\mathcal{S}|$ & $\# t$ && $|\mathcal{S}|$ & $\# t$ && $|\mathcal{S}|$ & $\# t$ \\ \midrule	
		a,100 & 2500 & 23.323 && 23.483 & 931 && 23.357 & 977 && 23.372 & 966 \\
		a,100 & 5000 & 11.922 && EA151 & - && EA152 & - && EA153 & -\\
		\midrule
		a,500 & 2500 & 114.942 && 116.681 & 264 && 117.041 & 213 && 116.604 & 277 \\
		a,500 & 5000 & 57.722 && EA551 & - && EA552 & - && EA553 & -\\
		\midrule
		\midrule
		r,100 & 2500 & 23.473 && ER121 & - && ER122 & - && ER123 & -\\
		r,100 & 5000 & 11.981 && ER151 & - && ER152 & - && ER153 & -\\
		\midrule
		r,500 & 2500 & 115.239 && ER521 & - && ER522 & - && ER523 & -\\
		r,500 & 5000 & 57.865 && ER551 & - && ER552 & - && ER553 & -\\
		\bottomrule
	\end{tabular}	
	\label{table:ea}
\end{table}

{\color{OrangeRed}
\begin{itemize}[leftmargin=*]
	\item Same 4 sets of instances used for heuristics used for EA.
	\item Run each set 6 times, different combinations of parameters, GGA/GPX'/GPN and strip width 2500 and 5000, 24 combinations total
	\item In EA output file to compare:
	\begin{itemize}[leftmargin=*]
		\item Proportion of times feasPacking/infeasPacking sets used instead of AHC
		\item Number of strips in best solution found
		\item Number of iterations of EA within the given time limit
		\item Fitness value of the best solution found
		\item solution quality $q = |\mathcal{S}|/t$ (=1 if lower bound met).
	\end{itemize}
	\item At the end of each EA iteration, add all strips from offspring to feasPacking set to use in post optimisation phase.
	\item Number of solution in initial population = 25.
	\item Time limit for EA - 300 seconds.
\end{itemize}
}

%--------------------------------------------------------------------------------------

\section{Postoptimisation}
\label{sec:postopt}
Given a collection $\mathcal{S}$ of subsets of a set $X$, an \emph{exact cover} is a subcollection $\mathcal{S}^*$ of $\mathcal{S}$ such that each element in $X$ is contained in exactly one subset in $\mathcal{S}^*$.

Consider an $m\times n$ binary matrix $X$. Let $M = \{1,2,\dotsc,m\}$ and $N = \{1,2,\dotsc,n\}$ be the rows and columns of the matrix respectively. Now, suppose each row $i \in M$ represents a strip, and each column $j \in N$ represents an item. Then, an element of the matrix $x_{ij} = 1$ iff item $j$ is on strip $i$. It can be said in this case that row $i$ \emph{covers} column $j$. Thus, the problem is to find a minimum cardinality subset of rows $S \subseteq M$ such that each column $j \in N$ is covered by exactly one row $i \in S$. This problem can be formulated as the following integer linear program.

\begin{subequations}
	\begin{alignat}{3}
		\text{minimise  } &\sum_{i \in M} c_i & \\[3pt]
		\text{subject to  } &\sum_{i \in M} x_{ij} c_i = 1 &\quad &\forall \hspace{1mm} j \in N \\[3pt]
		&c_i \in \{0,1\} & &\forall \hspace{1mm} i \in M
	\end{alignat}
\end{subequations}

\[c_i =
\begin{cases} 
1 & \text{if } i \in S \\
0 & \text{otherwise} 
\end{cases}
\]


The exact cover problem, determining whether a subcollection $\mathcal{S}^*$ exists, is a decision problem, and one of Karp's 21 NP-complete problems \cite{karp1972}. However, if we know that an exact cover does indeed exist, we can alter the problem to instead find the smallest subcollection.

Given a set of feasible strips, we can use this to find a solution to the SCSPP. Since the strips provided are already feasible, the complications associated with the vicinal sum constraint are eliminated.

One method of solving the exact cover problem is by using a recursive depth-first backtracking algorithm, dubbed ``Algorithm X'' by Donald Knuth \cite{knuth2000}, which is used to find all solutions. Given our problem, it is unecessary to find all solutions. Instead, we have adapted the procedure to only seach for solutions that improve upon the best solution found thus far. Ideally, we would use the entire set of feasible strips $\mathcal{F}$ to form the matrix, however this could include hundreds of millions of feasible strips. Instead, we chose to use the set $\mathcal{A}$ created during the EA, which contains feasible strips found during the algorithm.


{\color{myGreen}
\begin{itemize}[leftmargin=*]
	\item Exact cover formulation, NP-hard, state the IP, describe DLX
	\item cite Knuth \cite{knuth2000} dancing steps
	\item Use strips in feasPacking for post opt
	\item Compare with EA output - is a better solution found, or a solution with the same number of strips but a better fitness value?
	\item Is the post opt phase able to find a solution equal to the lowerbound?
	\item Post opt will only ever find a solution equal to or better than the solution found in EA, never worse
	\item Execution time
	\item Set cover problem is optimisation problem, find min number of sets
	\item exact cover problem is decision problem, does a set exist
	\item however since we add every item on its own strip to feasPacking, we know that a set exists
	\item problem is to find minimum number of strips that covers all items and contains every item exactly once
	\idone{$A = (a_{ij})$ - $m$ x $n$ matrix}
	\idone{$M = \{1, 2,..., m\}$ - rows of the matrix, each row $i \in M$ is a strip}
	\idone{$N = \{1, 2,...,n\}$ - columns of the matrix, each column $j \in N$ is an item}
	\idone{$(a_{ij}) = 1$ iff item $j$ is on strip $i$}
	\idone{Say that row $i$ covers column $j$ if $a_{ij} = 1$}
	\idone{Find the smallest number of strips $S \subseteq M$ that contains every item exactly once, i.e. union of strips $= \mathcal{I}$ and intersection $= \emptyset$}
	\idone{Find minimum cardinality subset $S \subseteq M$ of rows such that each column $j \in N$ is covered by exactly one row $i \in S$}
	\item Xpress mosel model
\end{itemize}
}





\subsection{Experimental Results - Postoptimisation}
\label{sub:exppostopt}

{\color{myGreen}
\begin{itemize}[leftmargin=*]
	\item
\end{itemize}
}

\section{Conclusion}
\label{sec:conclusion}

{\color{Orchid}
\begin{itemize}[leftmargin=*]
	\item Could use selected packings rather than all packings
\end{itemize}
}

	
%Citations
%\cite{becker2010},
%\cite{becker2015},
%\cite{coffman1978}, 
%\cite{coffman1984}, 
%\cite{dosa2007}, 
%\cite{eilon1971}, 
%\cite{falkenauer1992}, 
%\cite{falkenauer1996}, 
%\cite{garey1972}, 
%\cite{garey1979}, 
%\cite{garraffa2016}, 
%\cite{gilmore1961}, 
%\cite{gilmore1963}, 
%\cite{goulimis2004}, 
%\cite{haggkvist1977}, 
%\cite{hawa2018}, 
%\cite{hung1978}, 
%\cite{johnson1973}, 
%\cite{johnson1974fast}, 
%\cite{johnson1974worst}, 
%\cite{karp1972}, 
%\cite{knuth2000}, 
%\cite{korf2002}, 
%\cite{levine2004}, 
%\cite{lewis2009}, 
%\cite{lewis2011}, 
%\cite{lewis2017}, 
%\cite{mahadev1994}, 
%\cite{mahadev1995}, 
%\cite{malaguti2008}, 
%\cite{martello1990k}, 
%\cite{martello1990l}, 
%\cite{quiroz2015}.

\bibliographystyle{elsarticle-num}
\bibliography{includes/bibliography}

\end{document}










